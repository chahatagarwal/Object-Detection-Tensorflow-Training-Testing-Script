{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing all the dependencies for Custom Object Detection using Tensorflow\n",
    "\n",
    "NOTE: Remember to clone tensorflow from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "pYIPA24nbv9Y",
    "outputId": "1ac71a5d-6a46-4a20-c22a-93feba3792d5"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "n0L2NdW5b0kj",
    "outputId": "b71fc50f-c350-40ff-abc9-7735e07364d7"
   },
   "outputs": [],
   "source": [
    "!pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "9PWDNIVwQL7O",
    "outputId": "163d8ca5-e58b-4cf9-9209-fd71047caa5d"
   },
   "outputs": [],
   "source": [
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UVZOEdZTVUG"
   },
   "outputs": [],
   "source": [
    "!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "au7vUuKFTgpL"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import shutil\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import cv2 \n",
    "\n",
    "from PIL import Image\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Directory named \"Object_Detection\"\n",
    "\n",
    "Directory Structure:\n",
    "    \n",
    "    Object_Detection\n",
    "                |--data\n",
    "                    |--annotations (consist of .xml annotated files)\n",
    "                    |--images\n",
    "                |--models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDwzQTZwQHGv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIjEZFlYQA0B"
   },
   "outputs": [],
   "source": [
    "#creating two dir for training and testing\n",
    "!mkdir test_labels train_labels\n",
    "\n",
    "# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n",
    "# Moves the first 68/338 labels (20% of the labels) to the testing dir: `test_labels`\n",
    "!ls annotations/* | sort -R | head -68 | xargs -I{} mv {} test_labels/\n",
    "\n",
    "\n",
    "# Moves the rest of labels '270' labels to the training dir: `train_labels`\n",
    "!ls annotations/* | xargs -I{} mv {} train_labels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "y1PDnMjVTr7j",
    "outputId": "3f4de201-2835-4cf6-eb8d-32e783b797ed"
   },
   "outputs": [],
   "source": [
    "#helps to create .csv file for test and train labels. It also creates label_map.pbtxt\n",
    "def xml_to_csv(path):\n",
    "  classes_names = []\n",
    "  xml_list = []\n",
    "\n",
    "  for xml_file in glob.glob(path + '/*.xml'):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for member in root.findall('object'):\n",
    "      classes_names.append(member[0].text)\n",
    "      value = (root.find('filename').text.split(\".\")[0] + '.jpg',\n",
    "               int(root.find('size')[0].text),\n",
    "               int(root.find('size')[1].text),\n",
    "               member[0].text,\n",
    "               int(member[4][0].text),\n",
    "               int(member[4][1].text),\n",
    "               int(member[4][2].text),\n",
    "               int(member[4][3].text))\n",
    "      xml_list.append(value)\n",
    "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
    "  classes_names = list(set(classes_names))\n",
    "  classes_names.sort()\n",
    "  return xml_df, classes_names\n",
    "\n",
    "for label_path in ['train_labels', 'test_labels']:\n",
    "  image_path = os.path.join(os.getcwd(), label_path)\n",
    "  xml_df, classes = xml_to_csv(os.getcwd() + \"/\" + label_path)\n",
    "  xml_df.to_csv(f'{os.getcwd() +\"/\"+ label_path}.csv', index=None)\n",
    "  print(f'Successfully converted {label_path} xml to csv.')\n",
    "\n",
    "label_map_path = os.path.join(os.getcwd() + \"/label_map.pbtxt\")\n",
    "pbtxt_content = \"\"\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    pbtxt_content = (\n",
    "        pbtxt_content\n",
    "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
    "    )\n",
    "pbtxt_content = pbtxt_content.strip()\n",
    "with open(label_map_path, \"w\") as f:\n",
    "    f.write(pbtxt_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_RhWsxNa2OM"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgsbAuMOV2d7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"models/research/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-1kRwu9XXOx"
   },
   "outputs": [],
   "source": [
    "# compiles the proto buffers\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# exports PYTHONPATH environment var with research and slim paths\n",
    "os.environ['PYTHONPATH'] += ':./:./slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b844zLegYDsK"
   },
   "outputs": [],
   "source": [
    "# testing the model builder\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "JyYfEnqUYOFL",
    "outputId": "ef295b2e-13b2-44ca-b73b-074da6a0cfce"
   },
   "outputs": [],
   "source": [
    "#creates tf.records based on train and test labels\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "#change this to the base directory where your \"data/\" is \n",
    "data_base_url = 'Object_Detection/data/'\n",
    "\n",
    "#location of images\n",
    "image_dir = data_base_url +'images/'\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "  #change the labels as per your use case\n",
    "  if row_label == 'A':\n",
    "    return 1\n",
    "  elif row_label == 'B':\n",
    "    return 2\n",
    "  elif row_label == 'C':\n",
    "    return 3\n",
    "  else:\n",
    "    None\n",
    "\n",
    "def split(df, group):\n",
    "  data = namedtuple('data', ['filename', 'object'])\n",
    "  gb = df.groupby(group)\n",
    "  return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "\t  encoded_jpg = fid.read()\n",
    "\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "\timage = Image.open(encoded_jpg_io)\n",
    "\twidth, height = image.size\n",
    "\tfilename = group.filename.encode('utf8')\n",
    "\timage_format = b'jpg'\n",
    "\txmins = []\n",
    "\txmaxs = []\n",
    "\tymins = []\n",
    "\tymaxs = []\n",
    "\tclasses_text = []\n",
    "\tclasses = []\n",
    "\n",
    "\tfor index, row in group.object.iterrows():\n",
    "\t\txmins.append(row['xmin'] / width)\n",
    "\t\txmaxs.append(row['xmax'] / width)\n",
    "\t\tymins.append(row['ymin'] / height)\n",
    "\t\tymaxs.append(row['ymax'] / height)\n",
    "\t\tclasses_text.append(row['class'].encode('utf8'))\n",
    "\t\tclasses.append(class_text_to_int(row['class']))\n",
    "\ttf_example = tf.train.Example(features=tf.train.Features(feature={ \n",
    "\t\t'image/height': dataset_util.int64_feature(height),\n",
    "\t\t'image/width': dataset_util.int64_feature(width),\n",
    "\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
    "\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
    "\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
    "\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "\t\t'image/object/class/label': dataset_util.int64_list_feature(classes)}))\n",
    "\treturn tf_example\n",
    "\n",
    "#creates tfrecord for both csv's\n",
    "for csv in ['train_labels', 'test_labels']:\n",
    "\twriter = tf.io.TFRecordWriter(data_base_url + csv + '.record')\n",
    "\texamples = pd.read_csv(data_base_url + csv + '.csv')\n",
    "\tgrouped = split(examples, 'filename')\n",
    "\tfor group in grouped:\n",
    "\t\ttf_example = create_tf_example(group, image_dir)\n",
    "\t\twriter.write(tf_example.SerializeToString())\n",
    "\twriter.close()\n",
    "\toutput_path = data_base_url + csv + '.record'\n",
    "\tprint('Successfully created the TFRecords: {}'.format(data_base_url +csv + '.record'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yt249qUeaqTp"
   },
   "outputs": [],
   "source": [
    "# Some of the models to train on\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "    },\n",
    "}\n",
    "\n",
    "# Select a model from `MODELS_CONFIG`.\n",
    "selected_model = 'ssd_mobilenet_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vy3Z0G8pb1ap"
   },
   "outputs": [],
   "source": [
    "#the destination folder where the model will be saved\n",
    "#change this if you have a different working dir\n",
    "#Better to keep inside \"Object_Detection/models/research\" location\n",
    "\n",
    "DEST_DIR = os.getcwd() + '/pretrained_model'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "#selecting the model\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "\n",
    "#creating the downlaod link for the model selected\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "#checks if the model has already been downloaded, download it otherwise\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "#unzipping the model and extracting its content\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# creating an output file to save the model while training\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PHUsBNBjdfaF",
    "outputId": "c49dbd1f-9426-4b8e-8a34-b3236e064add"
   },
   "outputs": [],
   "source": [
    "#path to the config file\n",
    "!cat object_detection/samples/configs/ssd_mobilenet_v2_coco.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9ViCXc1f_6v8",
    "outputId": "db42e9ab-029c-41e5-cc67-507cd4979b71"
   },
   "outputs": [],
   "source": [
    "#path to the config file\n",
    "%%writefile object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n",
    "\n",
    "# paste the content of the config file in the same cell here.\n",
    "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
    "# Users should configure the fine_tune_checkpoint field in the train config as\n",
    "# well as the label_map_path and input_path fields in the train_input_reader and\n",
    "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
    "# should be configured.\n",
    "\n",
    "model {\n",
    "  ssd {\n",
    "    num_classes: 3\n",
    "    box_coder {\n",
    "      faster_rcnn_box_coder {\n",
    "        y_scale: 10.0\n",
    "        x_scale: 10.0\n",
    "        height_scale: 5.0\n",
    "        width_scale: 5.0\n",
    "      }\n",
    "    }\n",
    "    matcher {\n",
    "      argmax_matcher {\n",
    "        matched_threshold: 0.5\n",
    "        unmatched_threshold: 0.5\n",
    "        ignore_thresholds: false\n",
    "        negatives_lower_than_unmatched: true\n",
    "        force_match_for_each_row: true\n",
    "      }\n",
    "    }\n",
    "    similarity_calculator {\n",
    "      iou_similarity {\n",
    "      }\n",
    "    }\n",
    "    anchor_generator {\n",
    "      ssd_anchor_generator {\n",
    "        num_layers: 6\n",
    "        min_scale: 0.2\n",
    "        max_scale: 0.95\n",
    "        aspect_ratios: 1.0\n",
    "        aspect_ratios: 2.0\n",
    "        aspect_ratios: 0.5\n",
    "        aspect_ratios: 3.0\n",
    "        aspect_ratios: 0.3333\n",
    "      }\n",
    "    }\n",
    "    image_resizer {\n",
    "      fixed_shape_resizer {\n",
    "        height: 300\n",
    "        width: 300\n",
    "      }\n",
    "    }\n",
    "    box_predictor {\n",
    "      convolutional_box_predictor {\n",
    "        min_depth: 0\n",
    "        max_depth: 0\n",
    "        num_layers_before_predictor: 0\n",
    "        use_dropout: false\n",
    "        dropout_keep_probability: 0.8\n",
    "        kernel_size: 1\n",
    "        box_code_size: 4\n",
    "        apply_sigmoid_to_scores: false\n",
    "        conv_hyperparams {\n",
    "          activation: RELU_6,\n",
    "          regularizer {\n",
    "            l2_regularizer {\n",
    "              weight: 0.00004\n",
    "            }\n",
    "          }\n",
    "          initializer {\n",
    "            truncated_normal_initializer {\n",
    "              stddev: 0.03\n",
    "              mean: 0.0\n",
    "            }\n",
    "          }\n",
    "          batch_norm {\n",
    "            train: true,\n",
    "            scale: true,\n",
    "            center: true,\n",
    "            decay: 0.9997,\n",
    "            epsilon: 0.001,\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    feature_extractor {\n",
    "      type: 'ssd_mobilenet_v2'\n",
    "      min_depth: 16\n",
    "      depth_multiplier: 1.0\n",
    "      conv_hyperparams {\n",
    "        activation: RELU_6,\n",
    "        regularizer {\n",
    "          l2_regularizer {\n",
    "            weight: 0.00004\n",
    "          }\n",
    "        }\n",
    "        initializer {\n",
    "          truncated_normal_initializer {\n",
    "            stddev: 0.03\n",
    "            mean: 0.0\n",
    "          }\n",
    "        }\n",
    "        batch_norm {\n",
    "          train: true,\n",
    "          scale: true,\n",
    "          center: true,\n",
    "          decay: 0.9997,\n",
    "          epsilon: 0.001,\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    loss {\n",
    "      classification_loss {\n",
    "        weighted_sigmoid {\n",
    "        }\n",
    "      }\n",
    "      localization_loss {\n",
    "        weighted_smooth_l1 {\n",
    "        }\n",
    "      }\n",
    "      hard_example_miner {\n",
    "        num_hard_examples: 3000\n",
    "        iou_threshold: 0.99\n",
    "        loss_type: CLASSIFICATION\n",
    "        max_negatives_per_positive: 3\n",
    "        min_negatives_per_image: 3\n",
    "      }\n",
    "      classification_weight: 1.0\n",
    "      localization_weight: 1.0\n",
    "    }\n",
    "    normalize_loss_by_num_matches: true\n",
    "    post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 1e-8\n",
    "        iou_threshold: 0.6\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 100\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "  batch_size: 24\n",
    "  optimizer {\n",
    "    rms_prop_optimizer: {\n",
    "      learning_rate: {\n",
    "        exponential_decay_learning_rate {\n",
    "          initial_learning_rate: 0.004\n",
    "          decay_steps: 800720\n",
    "          decay_factor: 0.95\n",
    "        }\n",
    "      }\n",
    "      momentum_optimizer_value: 0.9\n",
    "      decay: 0.9\n",
    "      epsilon: 1.0\n",
    "    }\n",
    "  }\n",
    "  fine_tune_checkpoint: \"content/drive/My Drive/Object_Detection/models/research/pretrained_model/model.ckpt.data-00000-of-00001\"\n",
    "  fine_tune_checkpoint_type:  \"detection\"\n",
    "  # Note: The below line limits the training process to 200K steps, which we\n",
    "  # empirically found to be sufficient enough to train the pets dataset. This\n",
    "  # effectively bypasses the learning rate schedule (the learning rate will\n",
    "  # never decay). Remove the below line to train indefinitely.\n",
    "  num_steps: 200000\n",
    "  data_augmentation_options {\n",
    "    random_horizontal_flip {\n",
    "    }\n",
    "  }\n",
    "  data_augmentation_options {\n",
    "    ssd_random_crop {\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "train_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/content/drive/My Drive/Object_Detection/data/train_labels.record\"\n",
    "  }\n",
    "  label_map_path: \"/content/drive/My Drive/Object_Detection/data/label_map.pbtxt\"\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "  num_examples: 8000\n",
    "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
    "  # Remove the below line to evaluate indefinitely.\n",
    "  max_evals: 10\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "  tf_record_input_reader {\n",
    "    input_path: \"/content/drive/My Drive/Object_Detection/data/test_labels.record\"\n",
    "  }\n",
    "  label_map_path: \"/content/drive/My Drive/Object_Detection/data/label_map.pbtxt\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXwef-Icd4qB"
   },
   "source": [
    "List of things which can be modified in the above cell\n",
    " change number of classes - 3\n",
    " path of finetune checkpoint \n",
    " path of train_labels.record\n",
    " path of label map pbtxt -> train_labels\n",
    " path of test_labels.record\n",
    " path of label map pbtxt -> test_labels\n",
    " \n",
    " <-- If overfitting -->\n",
    " random_horizontal_flip\n",
    " ssd_random_crop\n",
    " use_dropout\n",
    " num_examples\n",
    " max_eval"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Outlier Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
